# Explainy ğŸ§ âœ¨
*A lightweight open-source explainability tool for AI/ML models.*

---

## ğŸš€ Overview
Explainy is a Python library that makes it simple to understand and interpret machine learning models.  
It provides **model-agnostic explanations** so you can debug, validate, and trust your AI.

---

## âœ¨ Features
- **Global Feature Importance** â€“ Identify which features matter most overall.  
- **Local Explanations** â€“ Understand why a single prediction was made.  
- **Counterfactuals** â€“ Discover minimal changes needed to flip predictions.  
- **Interactive Visualization** â€“ Explore results in a clean Streamlit UI.  

---

## ğŸ”§ Usage Example
```python
from explainy import Explainer
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Load data
X, y = load_breast_cancer(return_X_y=True, as_frame=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Create explainer
expl = Explainer(model, X_train, y_train)

# Global importance
print(expl.global_feature_importance())

# Local explanation
print(expl.local_explanation(X_test.iloc[0]))
```

---

## ğŸ–¥ï¸ Streamlit Demo
Run the interactive demo with:
```bash
streamlit run examples/demo_streamlit.py
```

---

## ğŸ“‚ Project Structure
```
explainy/
â”‚â”€â”€ core/
â”‚   â”œâ”€â”€ core.py           # Core methods of the package
â”‚   â”œâ”€â”€ visualizer.py     # Plotting + helpers
â”‚â”€â”€ examples/
â”‚   â”œâ”€â”€ demo_streamlit.py # Interactive demo
â”‚â”€â”€ README.md
```

---

## ğŸ¤ Contributing
We welcome contributions! Feel free to open issues or submit PRs.  
Check out our [Contributing Guide](CONTRIBUTING.md) (coming soon).

---

## ğŸ“œ License
MIT License Â© 2025
